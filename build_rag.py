import json
import os
import sys
import chromadb
from llama_index.core import Document, VectorStoreIndex, StorageContext, Settings
from llama_index.embeddings.ollama import OllamaEmbedding
from llama_index.vector_stores.chroma import ChromaVectorStore

# --- 1. ì„¤ì • ë° ê²½ë¡œ ---
BASE_DIR = "./data"
INPUT_JSON_PATH = os.path.join(BASE_DIR, "bokjiro_rag_final.json") # ì „ì²˜ë¦¬ ì™„ë£Œëœ íŒŒì¼
DB_PATH = "./chroma_db"           # ë²¡í„° DBê°€ ì €ì¥ë  ë¡œì»¬ í´ë”
COLLECTION_NAME = "welfare_policy" # DB ë‚´ë¶€ ì»¬ë ‰ì…˜ ì´ë¦„

# --- 2. ì„ë² ë”© ëª¨ë¸ ì„¤ì • (WSL -> Windows Ollama ì—°ê²°) ---
# ì£¼ì˜: Windowsì—ì„œ 'OLLAMA_HOST=0.0.0.0' ì„¤ì •ì´ ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
# host.docker.internalì€ WSLì—ì„œ Windows localhostë¥¼ ê°€ë¦¬í‚¤ëŠ” ì£¼ì†Œì…ë‹ˆë‹¤.
embed_model = OllamaEmbedding(
    model_name="mxbai-embed-large",
    base_url="http://host.docker.internal:11434", 
    ollama_additional_kwargs={"mirostat": 0},
    embed_batch_size=10 
)

# ì „ì—­ ì„¤ì •: ì„ë² ë”© ëª¨ë¸ ì§€ì • / LLMì€ ìƒì„± ë‹¨ê³„ê°€ ì•„ë‹ˆë¯€ë¡œ None
Settings.embed_model = embed_model
Settings.llm = None 

# --- 3. ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ---
def load_documents_from_json():
    """ì „ì²˜ë¦¬ëœ JSON íŒŒì¼ì„ LlamaIndex Document ê°ì²´ë¡œ ë³€í™˜"""
    if not os.path.exists(INPUT_JSON_PATH):
        print(f"âŒ ì…ë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {INPUT_JSON_PATH}")
        print("ë¨¼ì € 'preprocess_final.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

    with open(INPUT_JSON_PATH, 'r', encoding='utf-8') as f:
        data_list = json.load(f)

    documents = []
    print(f"ğŸ“‚ ë°ì´í„° íŒŒì¼ ë¡œë”© ì¤‘... (ì´ {len(data_list)}ê±´)")

    for item in data_list:
        # [í•µì‹¬] ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ë§Œë“  'í†µí•© í…ìŠ¤íŠ¸ í•„ë“œ'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        text_content = item.get('rag_full_text', '')
        
        if not text_content.strip():
            continue 

        # ë©”íƒ€ë°ì´í„° êµ¬ì„± (ê²€ìƒ‰ í›„ ì¶œì²˜ í‘œê¸°ë‚˜ í•„í„°ë§ì— ì‚¬ìš©)
        metadata = {
            "service_id": item.get('service_id', 'unknown'),
            "service_name": item.get('service_name', 'ì œëª© ì—†ìŒ'),
            "department": item.get('department', ''),
            "url": item.get('url', '')
        }

        # Document ê°ì²´ ìƒì„±
        doc = Document(
            text=text_content,
            metadata=metadata,
            # ì„ë² ë”©(ë²¡í„° ê³„ì‚°)í•  ë•Œ ì œì™¸í•  ë©”íƒ€ë°ì´í„° í‚¤ ì„¤ì •
            # (URLì´ë‚˜ IDëŠ” ì˜ë¯¸ë¡ ì  ìœ ì‚¬ì„±ê³¼ ê´€ê³„ì—†ìœ¼ë¯€ë¡œ ì œì™¸í•˜ëŠ” ê²Œ ì„±ëŠ¥ì— ì¢‹ìŒ)
            excluded_embed_metadata_keys=["url", "service_id", "service_name"] 
        )
        documents.append(doc)
    
    return documents

# --- 4. ì¸ë±ì‹±(ë²¡í„° ì €ì¥) ì‹¤í–‰ í•¨ìˆ˜ ---
def build_index():
    # 1. ë¬¸ì„œ ë³€í™˜
    documents = load_documents_from_json()
    if not documents:
        print("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print(f"âœ… ë¬¸ì„œ ë³€í™˜ ì™„ë£Œ: {len(documents)}ê°œì˜ Document ê°ì²´ ì¤€ë¹„ë¨.")

    # 2. ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    print(f"ğŸ’¾ ChromaDB ì´ˆê¸°í™” ì¤‘... (ì €ì¥ ê²½ë¡œ: {os.path.abspath(DB_PATH)})")
    db_client = chromadb.PersistentClient(path=DB_PATH)
    
    # ì»¬ë ‰ì…˜ ìƒì„± (ê¸°ì¡´ì— ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜´)
    chroma_collection = db_client.get_or_create_collection(COLLECTION_NAME)

    # 3. Vector Store ì„¤ì •
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    storage_context = StorageContext.from_defaults(vector_store=vector_store)

    # 4. ì¸ë±ì‹± (Embedding & Storing)
    print("ğŸš€ ë²¡í„° ë³€í™˜ ë° ì €ì¥ ì‹œì‘... (ë°ì´í„° ì–‘ì— ë”°ë¼ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤)")
    
    # from_documents í•¨ìˆ˜ê°€ ì„ë² ë”© -> ë²¡í„°í™” -> DB ì €ì¥ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    VectorStoreIndex.from_documents(
        documents,
        storage_context=storage_context,
        show_progress=True # ì§„í–‰ë¥  ë°” í‘œì‹œ
    )
    
    print("\nğŸ‰ [ì™„ë£Œ] ëª¨ë“  ë°ì´í„°ê°€ ë²¡í„° DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"   - DB ê²½ë¡œ: {DB_PATH}")
    print(f"   - ì»¬ë ‰ì…˜ëª…: {COLLECTION_NAME}")

if __name__ == "__main__":
    # ì‹¤í–‰ ì „ ì²´í¬ ì‚¬í•­ ì¶œë ¥
    print("âš ï¸  [Check] ìœˆë„ìš°ì—ì„œ 'ollama serve'ê°€ ì‹¤í–‰ ì¤‘ì¸ê°€ìš”?")
    print("âš ï¸  [Check] 'ollama pull mxbai-embed-large'ë¥¼ í•˜ì…¨ë‚˜ìš”?")
    print("---------------------------------------------------------")
    
    try:
        build_index()
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("íŒ: Connection ì˜¤ë¥˜ë¼ë©´ ìœˆë„ìš°ì˜ OLLAMA_HOST í™˜ê²½ë³€ìˆ˜ë‚˜ ë°©í™”ë²½ì„ í™•ì¸í•˜ì„¸ìš”.")