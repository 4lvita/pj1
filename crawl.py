import pandas as pd
import chardet
import asyncio
import os
import json
from playwright.async_api import async_playwright
from urllib.parse import urljoin

# --- 1. ì„¤ì • ë° ê²½ë¡œ ---
BASE_DATA_DIR = "./data"
DOWNLOAD_DIR = os.path.join(BASE_DATA_DIR, "attachments")
CSV_FILEPATH = os.path.join(BASE_DATA_DIR, 'welfare_info_20250722.csv')
JSON_SAVE_PATH = os.path.join(BASE_DATA_DIR, "bokjiro_scraped_data.json")

TIMEOUT_MS = 5000 
CONCURRENCY_LIMIT = 5
BATCH_SIZE = 10  # ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ì£¼ê¸° (10ê°œì”© ì²˜ë¦¬í•˜ê³  ì €ì¥)

os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# --- 2. CSV íŒŒì¼ ì½ê¸° ---
print("ë°ì´í„° íŒŒì¼ ë¡œë”© ì¤‘...")
try:
    with open(CSV_FILEPATH, 'rb') as f:
        data = f.read(100000)
    result = chardet.detect(data)
    encoding = result['encoding']
    df = pd.read_csv(CSV_FILEPATH, encoding=encoding)
    print(f"CSV ë¡œë“œ ì™„ë£Œ. ì´ {len(df)}ê°œì˜ ì„œë¹„ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
    exit()

# --- 3. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (ì´ì–´í•˜ê¸° ê¸°ëŠ¥) ---
def load_existing_data():
    if os.path.exists(JSON_SAVE_PATH):
        try:
            with open(JSON_SAVE_PATH, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•´ ì™„ë£Œëœ IDë“¤ì„ Setìœ¼ë¡œ ë§Œë“¦ (ê²€ìƒ‰ ì†ë„ O(1))
                finished_ids = {item['service_id'] for item in data}
                print(f"ğŸ”„ ê¸°ì¡´ ë°ì´í„° íŒŒì¼ ë°œê²¬: {len(data)}ê±´ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return data, finished_ids
        except Exception as e:
            print(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ (ìƒˆë¡œ ì‹œì‘): {e}")
            return [], set()
    else:
        print("âœ¨ ê¸°ì¡´ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        return [], set()

# --- 4. ë¹„ë™ê¸° í¬ë¡¤ë§ í•¨ìˆ˜ (ë‹¨ì¼) ---
async def scrape_single_service(context, sem, row, base_download_path):
    async with sem: 
        service_id = str(row['ì„œë¹„ìŠ¤ì•„ì´ë””'])
        service_name = str(row['ì„œë¹„ìŠ¤ëª…'])
        url = row['ì„œë¹„ìŠ¤URL']
        
        service_data = {
            "service_id": service_id,
            "service_name": service_name,
            "url": url,
            "summary": str(row['ì„œë¹„ìŠ¤ìš”ì•½']),
            "department": str(row['ì†Œê´€ë¶€ì²˜ëª…']),
            "ì§€ì›ëŒ€ìƒ": "",
            "ì„œë¹„ìŠ¤ ë‚´ìš©": "",
            "ì‹ ì²­ë°©ë²•": "",
            "ì¶”ê°€ì •ë³´": "",
            "files": []
        }

        if pd.isna(url) or pd.isna(service_id):
            return None

        page = await context.new_page()
        
        try:
            # í˜ì´ì§€ ì´ë™
            try:
                await page.goto(url, timeout=10000)
                await page.wait_for_load_state('networkidle', timeout=10000)
            except Exception:
                # print(f"  âš ï¸ [{service_id}] í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì•„ì›ƒ/ì˜¤ë¥˜ -> ê±´ë„ˆëœ€")
                await page.close()
                return service_data # ë¶€ë¶„ ë°ì´í„°ë¼ë„ ë°˜í™˜ (ë‚˜ì¤‘ì— ì±„ìš¸ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ)

            tabs = {
                "ì§€ì›ëŒ€ìƒ": page.locator(".custom-tabfolder .tabfolder-item").filter(has_text="ì§€ì›ëŒ€ìƒ"),
                "ì„œë¹„ìŠ¤ ë‚´ìš©": page.locator(".custom-tabfolder .tabfolder-item").filter(has_text="ì„œë¹„ìŠ¤ ë‚´ìš©"),
                "ì‹ ì²­ë°©ë²•": page.locator(".custom-tabfolder .tabfolder-item").filter(has_text="ì‹ ì²­ë°©ë²•"),
                "ì¶”ê°€ì •ë³´": page.locator(".custom-tabfolder .tabfolder-item").filter(has_text="ì¶”ê°€ì •ë³´")
            }
            
            content_pane_selector = '.cl-tabfolder-body > div[role="tabpanel"]:visible'
            
            for tab_name, tab_locator in tabs.items():
                try:
                    if await tab_locator.count() == 0:
                        continue
                        
                    await tab_locator.click(timeout=TIMEOUT_MS)
                    await page.wait_for_timeout(1000)
                    
                    visible_pane = page.locator(content_pane_selector)
                    
                    try:
                        await visible_pane.wait_for(state="visible", timeout=TIMEOUT_MS)
                        tab_text = await visible_pane.inner_text()
                        service_data[tab_name] = tab_text.strip()
                    except Exception:
                        continue

                    if tab_name == "ì¶”ê°€ì •ë³´":
                        download_buttons = visible_pane.locator('a[aria-label*="íŒŒì¼ë‹¤ìš´ë¡œë“œ"]')
                        count = await download_buttons.count()
                        
                        for i in range(count):
                            button = download_buttons.nth(i)
                            try:
                                async with page.expect_download(timeout=TIMEOUT_MS) as download_info:
                                    await button.click(timeout=TIMEOUT_MS)
                                
                                download = await download_info.value
                                original_filename = download.suggested_filename
                                new_filename = f"{service_id}_{original_filename}"
                                save_path = os.path.join(base_download_path, new_filename)
                                
                                # ì´ë¯¸ íŒŒì¼ì´ ìˆìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ìŠ¤í‚µ (ì„ íƒì‚¬í•­)
                                if not os.path.exists(save_path):
                                    await download.save_as(save_path)
                                    print(f"    ğŸ’¾ ì €ì¥: {new_filename}")
                                else:
                                    # print(f"    íŒŒì¼ ì´ë¯¸ ì¡´ì¬: {new_filename}")
                                    pass
                                    
                                service_data["files"].append(save_path)
                            except Exception:
                                pass
                                
                except Exception:
                    continue

            print(f"âœ… ì™„ë£Œ: {service_id} - {service_name}")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ ({service_id}): {e}")
        finally:
            await page.close()
            
        return service_data

# --- 5. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ---
async def main():
    # 1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    all_results, finished_ids = load_existing_data()
    
    # 2. ì•„ì§ ì²˜ë¦¬í•˜ì§€ ì•Šì€ í–‰ë§Œ í•„í„°ë§
    target_rows = []
    for index, row in df.iterrows():
        s_id = str(row['ì„œë¹„ìŠ¤ì•„ì´ë””'])
        if s_id not in finished_ids:
            target_rows.append(row)
            
    total_target = len(target_rows)
    print(f"ğŸš€ ìƒˆë¡œ ì²˜ë¦¬í•  ë°ì´í„°: {total_target}ê±´")

    if total_target == 0:
        print("ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(accept_downloads=True)
        sem = asyncio.Semaphore(CONCURRENCY_LIMIT)
        
        # 3. ë°°ì¹˜ ë‹¨ìœ„(BATCH_SIZE)ë¡œ ë‚˜ëˆ„ì–´ ì‹¤í–‰ ë° ì €ì¥
        # í•œ ë²ˆì— ë‹¤ ëŒë¦¬ì§€ ì•Šê³  ëŠì–´ì„œ ì €ì¥í•´ì•¼ ì¤‘ë‹¨ ì‹œ ì†ì‹¤ì„ ì¤„ì„
        for i in range(0, total_target, BATCH_SIZE):
            batch_rows = target_rows[i : i + BATCH_SIZE]
            tasks = []
            
            print(f"\n--- ë°°ì¹˜ ì‹œì‘ ({i+1} ~ {min(i+BATCH_SIZE, total_target)} / {total_target}) ---")
            
            for row in batch_rows:
                task = scrape_single_service(context, sem, row, DOWNLOAD_DIR)
                tasks.append(task)
            
            # ë°°ì¹˜ ì‹¤í–‰
            results = await asyncio.gather(*tasks)
            
            # ìœ íš¨í•œ ê²°ê³¼ë§Œ ì¶”ê°€
            valid_batch_results = [r for r in results if r is not None]
            all_results.extend(valid_batch_results)
            
            # 4. ì¤‘ê°„ ì €ì¥ (í•µì‹¬)
            try:
                with open(JSON_SAVE_PATH, 'w', encoding='utf-8') as f:
                    json.dump(all_results, f, ensure_ascii=False, indent=4)
                print(f"ğŸ’¾ í˜„ì¬ê¹Œì§€ ì´ {len(all_results)}ê±´ ì €ì¥ ì™„ë£Œ.")
            except Exception as e:
                print(f"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        await browser.close()
        print(f"\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (ìµœì¢… {len(all_results)}ê±´)")

# --- 6. ì‹¤í–‰ ---
if __name__ == "__main__":
    asyncio.run(main())